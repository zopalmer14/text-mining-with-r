---
title: "Text Mining with R - A Tidy Approach"
subtitle: "Applied Examples"
author: "Zach Palmer"
date: "2025-04-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Set Up & Load Data

```{r load-packages, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidytext)
library(igraph)
library(ggraph)
library(gutenbergr)
library(stringr)
library(topicmodels)
library(tm)
```

```{r search-gutenberg}
#gutenberg_metadata %>%
#  filter(str_detect(title, regex("The Skull", ignore_case=TRUE)))
```

```{r load-data}
# all text corpora downloaded from the Gutenberg Project

# The Time Machine, The War of the Worlds, The Invisible Man, and 
# The Door of the Wall, and Other Stories respectively 
hgwells = gutenberg_download(c(35, 36, 5230, 456), meta_fields = "title")

# A Journey to the Centre of the Earth and The Mysterious Island
jv = gutenberg_download(c(18857, 8993), meta_fields = "title")

# Second Variety, The Piper in the Woods, The Variable Man, The Defenders, 
# Mr. Spaceship, and The Skull respectively 
pkd = gutenberg_download(c(32032, 32832, 32154, 28767, 32522, 30255), meta_fields = "title")
```

```{r tidy-data, warning=FALSE, message=FALSE}
tidy_hgw = hgwells %>%
  select(-gutenberg_id) %>%
  mutate(author = "H.G. Wells") %>%
  group_by(title) %>%
  mutate(linenumber = row_number()) %>%
  ungroup() %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

tidy_jv = jv %>%
  select(-gutenberg_id) %>%
  mutate(author = "Jules Verne") %>%
  group_by(title) %>%
  mutate(linenumber = row_number()) %>%
  ungroup() %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

tidy_pkd = pkd %>%
  select(-gutenberg_id) %>%
  mutate(author = "Philip K. Dick") %>%
  group_by(title) %>%
  mutate(linenumber = row_number()) %>%
  ungroup() %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)
```

### Word Frequencies

#### Count Visualizations by Author

```{r}
tidy_books = tidy_hgw %>% 
  bind_rows(tidy_jv, tidy_pkd) %>%
  mutate(word = str_extract(word, "[a-z']+")) %>%
  drop_na()
```

```{r, fig.width=12, fig.height=8}
tidy_books %>%
  count(author, word) %>%
  group_by(author) %>%
  mutate(prop = n / sum(n)) %>%
  select(-n) %>%
  slice_max(prop, n = 10) %>%
  mutate(word = reorder_within(word, prop, author)) %>%
  ungroup() %>%
  ggplot(aes(prop, word, fill = author)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~author, ncol = 2, scales = "free") + 
  scale_y_reordered() +
  theme_bw() +
  labs(title = "Most Common Words Across Science Fiction Authors", x = "Frequency", y = NULL)
```

#### Word Frequency Comparisons Between Authors

```{r}
word_frequency = tidy_books %>%
  count(author, word) %>%
  group_by(author) %>%
  mutate(proportion = n / sum(n)) %>% 
  select(-n) %>% 
  pivot_wider(names_from = author, values_from = proportion) %>%
  pivot_longer(c(`Jules Verne`, `Philip K. Dick`), names_to = "author", 
               values_to = "proportion")
```

```{r}
word_frequency %>% head(10)
```

```{r, warning=FALSE, fig.width=12, fig.height=8}
word_frequency %>%
  ggplot(aes(x = proportion, y = `H.G. Wells`, 
             color = abs(`H.G. Wells` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = scales::percent_format()) +
  scale_y_log10(labels = scales::percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), 
                       low = "darkslategray4", high = "gray75") +
  facet_wrap(~author, ncol = 2) +
  theme_bw() +
  theme(legend.position = "none") +
  labs(title = "Comparison of Word Usage Between Science Fiction Authors", 
       y = "H.G. Wells", x = NULL)
```

### Sentiment Analysis

```{r}
get_sentiments("bing") %>% head()
```

#### H.G. Wells

```{r}
hg_sentiment = tidy_books %>%
  filter(author == "H.G. Wells") %>%
  inner_join(get_sentiments("bing")) %>%
  count(title, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
```

```{r, fig.width=15, fig.height=9}
hg_sentiment %>%
  ggplot(aes(index, sentiment, fill = title)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~title, ncol = 2, scales = "free_x") +
  labs(title = "Text Sentiment Across H.G. Wells Novels",
       x = "Index", y = "Net Word Sentiment") +
  theme_bw()
```

#### Jules Verne

```{r}
jv_sentiment = tidy_books %>%
  filter(author == "Jules Verne") %>%
  inner_join(get_sentiments("bing")) %>%
  count(title, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
```

```{r, fig.width=18, fig.height=6}
jv_sentiment %>%
  ggplot(aes(index, sentiment, fill = title)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~title, ncol = 2, scales = "free_x") +
  labs(title = "Text Sentiment Across Jules Verne Novels",
       x = "Index", y = "Net Word Sentiment") +
  theme_bw()
```

#### Philip K. Dick

```{r}
pkd_sentiment = tidy_books %>%
  filter(author == "Philip K. Dick") %>%
  inner_join(get_sentiments("bing")) %>%
  count(title, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
```

```{r, fig.width=12, fig.height=9}
pkd_sentiment %>%
  ggplot(aes(index, sentiment, fill = title)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~title, ncol = 2, scales = "free_x") +
  labs(title = "Text Sentiment Across Philip K. Dick Stories",
       x = "Index", y = "Net Word Sentiment") +
  theme_bw()
```

### Comparing Sentiment Dictionaries

```{r}
mysterious_island = tidy_books %>%
  filter(title == "The Mysterious Island")
```

```{r}
afinn = mysterious_island %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")

bing = mysterious_island %>% 
  inner_join(get_sentiments("bing")) %>%
  mutate(method = "Bing et al.")

nrc = mysterious_island %>% 
  inner_join(get_sentiments("nrc") %>% filter(sentiment %in% c("positive", "negative"))) %>%
  mutate(method = "NRC")

bing_and_nrc = bing %>% 
  bind_rows(nrc) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative)

afinn_bing_and_nrc = afinn %>%
  bind_rows(bing_and_nrc)
```

```{r, fig.width=12, fig.height=9}
afinn_bing_and_nrc %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y") +
  labs(title = "Comparing Text Sentiment Dictionary Results for The Mysterious Island by Jules Verne",
       x = "Index", y = "Net Word Sentiment") +
  theme_bw()
```

### Word & Document Frequency: tf-idf

### Bigrams & Relationships Between Words

```{r}
# taken from Text Mining with R: A Tidy Approach, section 4.1.5
count_bigrams = function(dataset) {
  dataset %>%
    unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
    separate(bigram, c("word1", "word2"), sep = " ") %>%
    filter(!word1 %in% stop_words$word,
           !word2 %in% stop_words$word) %>%
    count(word1, word2, sort = TRUE)
}

visualize_bigrams = function(bigrams) {
  set.seed(2016)
  a = grid::arrow(type = "closed", length = unit(.15, "inches"))
  
  bigrams %>%
    graph_from_data_frame() %>%
    ggraph(layout = "fr") +
    geom_edge_link(aes(edge_alpha = n), show.legend = FALSE, arrow = a) +
    geom_node_point(color = "lightblue", size = 5) +
    geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
    theme_void()
}
```

### Topic Modeling

```{r}
data("AssociatedPress")
AssociatedPress
```

```{r}
ap_lda = LDA(AssociatedPress, k = 2, control = list(seed = 1234))
ap_lda
```

#### Term-Topic Probabilities

```{r}
ap_topics = tidy(ap_lda, matrix = "beta")
ap_topics
```

```{r}
ap_top_terms = ap_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>% 
  ungroup() %>%
  arrange(topic, -beta)

ap_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() +
  theme_bw()
```

```{r}
beta_wide = ap_topics %>%
  mutate(topic = paste0("topic", topic)) %>%
  pivot_wider(names_from = topic, values_from = beta) %>% 
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1))

beta_wide
```

```{r, fig.width=12, fig.height=8}
beta_wide %>%
  arrange(desc(abs(log_ratio))) %>%
  head(20) %>%
  mutate(term = reorder(term, log_ratio)) %>%
  ggplot(aes(log_ratio, term)) +
  geom_col(fill = "dodgerblue") +
  theme_bw() + 
  theme(title = element_text(size = 14), 
        axis.title = element_text(size = 14), 
        axis.text = element_text(size = 12)) +
  labs(title = "Terms with the Greatest Difference in β Between Topic 2 and Topic 1",
       x = "Log2 Ratio of β in Topic 2 / Topic 1")
```

### Example: Use LDA on Novels from Different Authors

```{r}
# Jules Verne, HG Wells, Jane Austen, Charles Dickens
titles = c("A Journey to the Centre of the Earth", 
            "The War of the Worlds",
            "Sense and Sensibility", 
            "Great Expectations")
```

```{r}
books = gutenberg_works(title %in% titles) %>%
  gutenberg_download(meta_fields = "title")
```

```{r}
books %>% distinct(title)
```

```{r}
# divide into documents, each representing one chapter
by_chapter = books %>%
  group_by(title) %>%
  mutate(chapter = cumsum(str_detect(
    text, regex("^chapter ", ignore_case = TRUE)
  ))) %>%
  ungroup() %>%
  filter(chapter > 0) %>%
  unite(document, title, chapter)

by_chapter
```

```{r}
# split into words, then find document-word counts
by_chapter_word = by_chapter %>%
  unnest_tokens(word, text)

word_counts = by_chapter_word %>%
  anti_join(stop_words) %>%
  count(document, word, sort = TRUE)

word_counts
```

#### Apply LDA on Chapters

```{r}
chapters_dtm = word_counts %>%
  cast_dtm(document, word, n)

chapters_dtm
```

```{r}
chapters_lda = LDA(chapters_dtm, k = 4, control = list(seed = 1234))
chapters_lda
```

```{r}
chapter_topics = tidy(chapters_lda, matrix = "beta")
chapter_topics
```

```{r}
top_terms = chapter_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 5) %>% 
  ungroup() %>%
  arrange(topic, -beta)

top_terms
```

```{r, fig.width=15, fig.height=9}
top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~topic, scales = "free") +
  scale_y_reordered() +
  theme_bw() + 
  theme(title = element_text(size = 14), 
        axis.title = element_text(size = 14), 
        axis.text = element_text(size = 12)) +
  labs(title = "Most Frequently Generated Terms From Each Topic")
```


